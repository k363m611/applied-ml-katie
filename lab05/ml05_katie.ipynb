{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 5 Project (Ensemble Models)\n",
    "\n",
    "- **Author:** Katie McGaughey \n",
    "- **Date:** 2025-04-11\n",
    "- **Objective:** Utilizing data about wine quality to train & test ensemble ML models\n",
    "\n",
    "This code base is being created in the course of completing module 5 of CSIS 44-670 from NW Missouri University. In this Jupyter Notebook which we will analyze data representing quality of wine. This data is sourced from the UCI Machine Learning Repository -> https://archive.ics.uci.edu/ml/datasets/Wine+Quality\n",
    "\n",
    "> Data originally published by: P. Cortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis.\n",
    "> Modeling wine preferences by data mining from physicochemical properties.\n",
    "> In Decision Support Systems, Elsevier, 47(4):547–553, 2009.\n",
    "\n",
    "Direct download link to raw csv: https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv \n",
    "\n",
    "In this lab we're exploring the prediction of the **quality** (scale of 0 to 10 as rated by wine tasters) of the wines in the dataset according to their features. This section from the assignment explains the featuers & goal well.\n",
    "\n",
    "The dataset includes 11 physicochemical input variables (features):\n",
    "---------------------------------------------------------------\n",
    "\n",
    "- fixed acidity          mostly tartaric acid\n",
    "- volatile acidity       mostly acetic acid (vinegar)\n",
    "- citric acid            can add freshness and flavor\n",
    "- residual sugar         remaining sugar after fermentation\n",
    "- chlorides              salt content\n",
    "- free sulfur dioxide    protects wine from microbes\n",
    "- total sulfur dioxide   sum of free and bound forms\n",
    "- density                related to sugar content\n",
    "- pH                     acidity level (lower = more acidic)\n",
    "- sulphates              antioxidant and microbial stabilizer\n",
    "- alcohol                % alcohol by volume\n",
    "\n",
    "The target variable is:\n",
    "- quality (integer score from 0 to 10, rated by wine tasters)\n",
    "\n",
    "We will simplify this target into three categories:\n",
    "- low (3–4), medium (5–6), high (7–8) to make classification feasible.\n",
    "- we will also make this numeric (we want both for clarity)\n",
    "The dataset contains 1599 samples and 12 columns (11 features + target). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1. Import and Inspect the Data\n",
    "\n",
    "In this section we load a sample dataset from Seaborn's library into a DataFrame and do a standard set of what I'll call \"getting to know you\" methods to get a view of the dataset schema, its contents, the proportions of missing values, and any correlations that exist between the numerical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1599 entries, 0 to 1598\n",
      "Data columns (total 12 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   fixed acidity         1599 non-null   float64\n",
      " 1   volatile acidity      1599 non-null   float64\n",
      " 2   citric acid           1599 non-null   float64\n",
      " 3   residual sugar        1599 non-null   float64\n",
      " 4   chlorides             1599 non-null   float64\n",
      " 5   free sulfur dioxide   1599 non-null   float64\n",
      " 6   total sulfur dioxide  1599 non-null   float64\n",
      " 7   density               1599 non-null   float64\n",
      " 8   pH                    1599 non-null   float64\n",
      " 9   sulphates             1599 non-null   float64\n",
      " 10  alcohol               1599 non-null   float64\n",
      " 11  quality               1599 non-null   int64  \n",
      "dtypes: float64(11), int64(1)\n",
      "memory usage: 150.0 KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier,\n",
    "    AdaBoostClassifier,\n",
    "    GradientBoostingClassifier,\n",
    "    BaggingClassifier,\n",
    "    VotingClassifier,\n",
    ")\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    ")\n",
    "\n",
    "# Load the dataset (download from UCI and save in the same folder)\n",
    "df = pd.read_csv(\"winequality-red.csv\", sep=\";\")\n",
    "\n",
    "# Display structure and first few rows\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Prepare the Data\n",
    "\n",
    "In this section we clean the data, do feature engineering, set up helper functions and generally get the data ready for the ML algorithms.\n",
    "\n",
    "We will create a **quality_to_label** function to stratify the 0 to 10 numerical grading scheme into a simpler \"low/medium/high\" scheme. We'll also work this scheme backwards to assign low/medium/high quality wines to the integers between 0 and 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define helper function that:\n",
    "\n",
    "# Takes one input, the quality (which we will temporarily name q while in the function)\n",
    "# And returns a string of the quality label (low, medium, high)\n",
    "# This function will be used to create the quality_label column\n",
    "def quality_to_label(q):\n",
    "    if q <= 4:\n",
    "        return \"low\"\n",
    "    elif q <= 6:\n",
    "        return \"medium\"\n",
    "    else:\n",
    "        return \"high\"\n",
    "\n",
    "\n",
    "# Call the apply() method on the quality column to create the new quality_label column\n",
    "df[\"quality_label\"] = df[\"quality\"].apply(quality_to_label)\n",
    "\n",
    "\n",
    "# Then, create a numeric column for modeling: 0 = low, 1 = medium, 2 = high\n",
    "def quality_to_number(q):\n",
    "    if q <= 4:\n",
    "        return 0\n",
    "    elif q <= 6:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "\n",
    "df[\"quality_numeric\"] = df[\"quality\"].apply(quality_to_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Feature Selection & Justification\n",
    "\n",
    "In thsi section we will set up the X values (features) and Y value (target) for the ML algorithms to eventually train on and test against.\n",
    "\n",
    "We will drop unnecessary columns for the sake of keeping the model clean. In our case, the quality column is not linearly separable from the target (we used it to create the target), therefore we don't really want to model to consider these features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input features (X) and target (y)\n",
    "# Features: all columns except 'quality' and 'quality_label' and 'quality_numberic' - drop these from the input array\n",
    "# Target: quality_label (the new column we just created)\n",
    "X = df.drop(columns=[\"quality\", \"quality_label\", \"quality_numeric\"])  # Features\n",
    "y = df[\"quality_numeric\"]  # Target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Split to Train & Test\n",
    "\n",
    "In this section we create two datasets from our input - one for model **training** and one for model **testing**. This will give the model something to work with, then something to prove to us that it's capable of what it was trained to do. This sets up the evaluation we'll be doing later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test split (stratify to preserve class balance)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5: Evaluate Model Performance\n",
    "\n",
    "In this section we'll be using **two** models from the below table to train against our training dataset and evaluate against our evaluation dataset. \n",
    "\n",
    "Below is a list of  9 model variations. Choose two to focus on for your comparison. \n",
    "\n",
    "|Option|Model Name|Notes|\n",
    "|---|---|---|\n",
    "|1|Random Forest (100)|A strong baseline model using 100 decision trees.|\n",
    "|2|Random Forest (200, max_depth=10)|Adds more trees, but limits tree depth to reduce overfitting.|\n",
    "|3|AdaBoost (100)|Boosting method that focuses on correcting previous errors.|\n",
    "|4|AdaBoost (200, lr=0.5)|More iterations and slower learning for better generalization.|\n",
    "|5|Gradient Boosting (100)|Boosting approach using gradient descent.|\n",
    "|6|Voting (DT + SVM + NN)|Combines diverse models by averaging their predictions.|\n",
    "|7|Voting (RF + LR + KNN)|Another mix of different model types.|\n",
    "|8|Bagging (DT, 100)|Builds many trees in parallel on different samples.|\n",
    "|9|MLP Classifier|A basic neural network with one hidden layer.|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Helper function to train and evaluate models\n",
    "def evaluate_model(name, model, X_train, y_train, X_test, y_test, results):\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    train_acc = accuracy_score(y_train, y_train_pred)\n",
    "    test_acc = accuracy_score(y_test, y_test_pred)\n",
    "    train_f1 = f1_score(y_train, y_train_pred, average=\"weighted\")\n",
    "    test_f1 = f1_score(y_test, y_test_pred, average=\"weighted\")\n",
    "\n",
    "    print(f\"\\n{name} Results\")\n",
    "    print(\"Confusion Matrix (Test):\")\n",
    "    print(confusion_matrix(y_test, y_test_pred))\n",
    "    print(f\"Train Accuracy: {train_acc:.4f}, Test Accuracy: {test_acc:.4f}\")\n",
    "    print(f\"Train F1 Score: {train_f1:.4f}, Test F1 Score: {test_f1:.4f}\")\n",
    "\n",
    "    results.append(\n",
    "        {\n",
    "            \"Model\": name,\n",
    "            \"Train Accuracy\": train_acc,\n",
    "            \"Test Accuracy\": test_acc,\n",
    "            \"Train F1\": train_f1,\n",
    "            \"Test F1\": test_f1,\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the above helper function we can efficiently train, test, then print to the console the evaluation results of the chosen models. While I've included the code for all models, only models **#5** and **#7** will be run & included, per lab instructions (choose 2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gradient Boosting (100) Results\n",
      "Confusion Matrix (Test):\n",
      "[[  0  13   0]\n",
      " [  3 247  14]\n",
      " [  0  16  27]]\n",
      "Train Accuracy: 0.9601, Test Accuracy: 0.8562\n",
      "Train F1 Score: 0.9584, Test F1 Score: 0.8411\n",
      "\n",
      "Voting (RF + LR + KNN) Results\n",
      "Confusion Matrix (Test):\n",
      "[[  0  13   0]\n",
      " [  0 256   8]\n",
      " [  0  27  16]]\n",
      "Train Accuracy: 0.9132, Test Accuracy: 0.8500\n",
      "Train F1 Score: 0.8933, Test F1 Score: 0.8185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aaron/Documents/Git_Repos/GradSchool/44670/applied-ml-gillespie/.venv/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# List to store results\n",
    "results = []\n",
    "\n",
    "# # 1. Random Forest\n",
    "# evaluate_model(\n",
    "#     \"Random Forest (100)\",\n",
    "#     RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "#     X_train,\n",
    "#     y_train,\n",
    "#     X_test,\n",
    "#     y_test,\n",
    "#     results,\n",
    "# )\n",
    "\n",
    "# # 2. Random Forest (200, max depth=10) \n",
    "# evaluate_model(\n",
    "#     \"Random Forest (200, max_depth=10)\",\n",
    "#     RandomForestClassifier(n_estimators=200, max_depth=10, random_state=42),\n",
    "#     X_train,\n",
    "#     y_train,\n",
    "#     X_test,\n",
    "#     y_test,\n",
    "#     results,\n",
    "# )\n",
    "\n",
    "# # 3. AdaBoost \n",
    "# evaluate_model(\n",
    "#     \"AdaBoost (100)\",\n",
    "#     AdaBoostClassifier(n_estimators=100, random_state=42),\n",
    "#     X_train,\n",
    "#     y_train,\n",
    "#     X_test,\n",
    "#     y_test,\n",
    "#     results,\n",
    "# )\n",
    "\n",
    "# # 4. AdaBoost (200, lr=0.5) \n",
    "# evaluate_model(\n",
    "#     \"AdaBoost (200, lr=0.5)\",\n",
    "#     AdaBoostClassifier(n_estimators=200, learning_rate=0.5, random_state=42),\n",
    "#     X_train,\n",
    "#     y_train,\n",
    "#     X_test,\n",
    "#     y_test,\n",
    "#     results,\n",
    "# )\n",
    "\n",
    "# 5. Gradient Boosting\n",
    "evaluate_model(\n",
    "    \"Gradient Boosting (100)\",\n",
    "    GradientBoostingClassifier(\n",
    "        n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42\n",
    "    ),\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    results,\n",
    ")\n",
    "\n",
    "# # 6. Voting Classifier (DT, SVM, NN) \n",
    "# voting1 = VotingClassifier(\n",
    "#     estimators=[\n",
    "#         (\"DT\", DecisionTreeClassifier()),\n",
    "#         (\"SVM\", SVC(probability=True)),\n",
    "#         (\"NN\", MLPClassifier(hidden_layer_sizes=(50,), max_iter=1000)),\n",
    "#     ],\n",
    "#     voting=\"soft\",\n",
    "# )\n",
    "# evaluate_model(\n",
    "#     \"Voting (DT + SVM + NN)\", voting1, X_train, y_train, X_test, y_test, results\n",
    "# )\n",
    "\n",
    "# 7. Voting Classifier (RF, LR, KNN) \n",
    "voting2 = VotingClassifier(\n",
    "    estimators=[\n",
    "        (\"RF\", RandomForestClassifier(n_estimators=100)),\n",
    "        (\"LR\", LogisticRegression(max_iter=1000)),\n",
    "        (\"KNN\", KNeighborsClassifier()),\n",
    "    ],\n",
    "    voting=\"soft\",\n",
    ")\n",
    "evaluate_model(\n",
    "    \"Voting (RF + LR + KNN)\", voting2, X_train, y_train, X_test, y_test, results\n",
    ")\n",
    "\n",
    "# # 8. Bagging \n",
    "# evaluate_model(\n",
    "#     \"Bagging (DT, 100)\",\n",
    "#     BaggingClassifier(\n",
    "#         estimator=DecisionTreeClassifier(), n_estimators=100, random_state=42\n",
    "#     ),\n",
    "#     X_train,\n",
    "#     y_train,\n",
    "#     X_test,\n",
    "#     y_test,\n",
    "#     results,\n",
    "# )\n",
    "\n",
    "# # 9. MLP Classifier \n",
    "# evaluate_model(\n",
    "#     \"MLP Classifier\",\n",
    "#     MLPClassifier(hidden_layer_sizes=(100,), max_iter=1000, random_state=42),\n",
    "#     X_train,\n",
    "#     y_train,\n",
    "#     X_test,\n",
    "#     y_test,\n",
    "#     results,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 6: Compare Results\n",
    "\n",
    "In this section we will compare the performance of the chosen models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary of All Models:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Train F1</th>\n",
       "      <th>Test F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gradient Boosting (100)</td>\n",
       "      <td>0.960125</td>\n",
       "      <td>0.85625</td>\n",
       "      <td>0.95841</td>\n",
       "      <td>0.841106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Voting (RF + LR + KNN)</td>\n",
       "      <td>0.913213</td>\n",
       "      <td>0.85000</td>\n",
       "      <td>0.89328</td>\n",
       "      <td>0.818465</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Model  Train Accuracy  Test Accuracy  Train F1   Test F1\n",
       "0  Gradient Boosting (100)        0.960125        0.85625   0.95841  0.841106\n",
       "1   Voting (RF + LR + KNN)        0.913213        0.85000   0.89328  0.818465"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a table of results \n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "print(\"\\nSummary of All Models:\")\n",
    "\n",
    "# Sort by 'Test Accuracy' in descending order\n",
    "df_sorted = results_df.sort_values(by=\"Test Accuracy\", ascending=False)\n",
    "\n",
    "# Print the sorted DataFrame\n",
    "display(df_sorted)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 7: Conclusions & Insights\n",
    "\n",
    "In this section we will analyze and discuss the results. We'll also utilize results from another student in my class who's performed this same lab assignment and chose different models for their evaluation.\n",
    "\n",
    "> Referenced work by [Brett Neely](https://github.com/bncodes19) - see [his GitHub Repo for this lab](https://github.com/bncodes19/applied-ml-bneely/blob/main/lab05/ensemble-neely.ipynb)\n",
    "\n",
    "Brett chose to analyze the AdaBoost (100) and MLP Classifier models, (3 & 9, respectively, from the table). The results Brett obtained were as follows:\n",
    "\n",
    "||Model|Train Accuracy|Test Accuracy|Train F1|Test F1|\n",
    "|---|---|---|---|---|---|\n",
    "|0|AdaBoost (100)|0.834246|0.82500|0.820863|0.815803|\n",
    "|1|MLP Classifier|0.851446|0.84375|0.814145|0.807318|\n",
    "\n",
    "Merging Brett's results and the results I obtained for the Gradient Boosting (100) and Voting (RF + LR + KNN) models & sorting them by test **accuracy**:\n",
    "\n",
    "||Model|Train Accuracy|Test Accuracy|Train F1|Test F1|\n",
    "|---|---|---|---|---|---|\n",
    "|5|Gradient Boosting (100)|0.960125|0.85625|0.95841|0.841106|\n",
    "|7|Voting (RF + LR + KNN)|0.913213|0.85000|0.89328|0.818465|\n",
    "|9|MLP Classifier|0.851446|0.84375|0.814145|0.807318|\n",
    "|3|AdaBoost (100)|0.834246|0.82500|0.820863|0.815803|\n",
    "\n",
    "**Accuracy** is a measure of what proportion of the predictions were correct. The formula for accuracy is what you'd expect:\n",
    "\n",
    "$$\\text{Accuracy} = \\frac{\\text{Number of Correct Predictions}}{\\text{Total Number of Predictions}}$$\n",
    "\n",
    "The highest accuracy model was Gradient Boosting (100), which was correct in 96% of its predictions. The to the lowest accuracy model, AdaBoost (100), still performed respectably, obtaining the correct result 82.5% of the time. That's the difference between earning an A and a B. Not terrible.\n",
    "\n",
    "Sorting by the test **F1 Score** you get a slightly different order:\n",
    "\n",
    "||Model|Train Accuracy|Test Accuracy|Train F1|Test F1|\n",
    "|---|---|---|---|---|---|\n",
    "|5|Gradient Boosting (100)|0.960125|0.85625|0.95841|0.841106|\n",
    "|7|Voting (RF + LR + KNN)|0.913213|0.85000|0.89328|0.818465|\n",
    "|3|AdaBoost (100)|0.834246|0.82500|0.820863|0.815803|\n",
    "|9|MLP Classifier|0.851446|0.84375|0.814145|0.807318|\n",
    "\n",
    "**F1 score** is a single metric that provides a balanced measure of a model's performance, combining two crucial metrics: **precision** and **recall**.\n",
    "\n",
    "$$F1 \\ Score = 2 \\times \\frac{Precision \\times Recall}{Precision + Recall} = \\frac{2 \\cdot TP}{2 \\cdot TP + FN + FP}$$\n",
    "\n",
    "The model with the best F1 score was again Gradient Boosting (100). The lowest accuracy model actually had a slightly better F1 score than the lowest-scoring F1 Test model: MLP Classifier.\n",
    "\n",
    "### Overall conclusion\n",
    "\n",
    "For the purposes of this dataset in prediction the classification of the quality of wine there is no \"bad\" models to choose from. However, there are meaningful differences in the models tested. The Gradient Boosting (100) model is the strongest choice. This model uses the Gradient Boosting technique with a hyperparameter of 100. \n",
    "\n",
    "> **Gradient Boosting** is a machine learning technique that builds an ensemble of weak prediction models, typically decision trees. It works in a stage-wise fashion, where each new model is trained to correct the errors made by the previous models. The \"gradient\" part refers to the use of gradient descent in the optimization process to find the best way to combine the weak learners.  \n",
    "> <cite>source: Gemini</cite>\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
