{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 5: Ensemble Machine Learning – Wine Quality Dataset\n",
    "**Author:** Katie McGaughey  \n",
    "**Date:** April 11, 2025  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction: \n",
    "This notebook explores red wine quality classification (low, medium, high) using ensemble models applied to the UCI Wine Quality Dataset from the UCI Machine Learning Repository. We evaluate two approaches—Random Forest and a Voting Classifier—based on 11 physicochemical attributes, comparing their performance using accuracy and F1 scores. The objective is to determine the most effective model for predicting wine quality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1. Import and Inspect the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1599 entries, 0 to 1598\n",
      "Data columns (total 12 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   fixed acidity         1599 non-null   float64\n",
      " 1   volatile acidity      1599 non-null   float64\n",
      " 2   citric acid           1599 non-null   float64\n",
      " 3   residual sugar        1599 non-null   float64\n",
      " 4   chlorides             1599 non-null   float64\n",
      " 5   free sulfur dioxide   1599 non-null   float64\n",
      " 6   total sulfur dioxide  1599 non-null   float64\n",
      " 7   density               1599 non-null   float64\n",
      " 8   pH                    1599 non-null   float64\n",
      " 9   sulphates             1599 non-null   float64\n",
      " 10  alcohol               1599 non-null   float64\n",
      " 11  quality               1599 non-null   int64  \n",
      "dtypes: float64(11), int64(1)\n",
      "memory usage: 150.0 KB\n",
      "\n",
      "First Rows:\n",
      "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
      "0            7.4              0.70         0.00             1.9      0.076   \n",
      "1            7.8              0.88         0.00             2.6      0.098   \n",
      "2            7.8              0.76         0.04             2.3      0.092   \n",
      "3           11.2              0.28         0.56             1.9      0.075   \n",
      "4            7.4              0.70         0.00             1.9      0.076   \n",
      "\n",
      "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
      "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
      "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
      "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
      "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
      "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
      "\n",
      "   alcohol  quality  \n",
      "0      9.4        5  \n",
      "1      9.8        5  \n",
      "2      9.8        5  \n",
      "3      9.8        6  \n",
      "4      9.4        5  \n"
     ]
    }
   ],
   "source": [
    "# Load dataset from local file\n",
    "df = pd.read_csv(\"winequality-red.csv\", sep=\";\")\n",
    "print(\"Dataset Info:\")\n",
    "df.info()\n",
    "print(\"\\nFirst Rows:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reflection \n",
    "##### - **Data Structure:** 1599 samples, 12 columns (11 features + quality), all numeric with no missing values.  \n",
    "##### - **Features:** Physicochemical properties (e.g., alcohol, pH) likely influence quality scores.   \n",
    "##### - **Target:** Quality (3–8) requires categorization for classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Data Exploration and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class Distribution:\n",
      "quality_numeric\n",
      "1    0.824891\n",
      "2    0.135710\n",
      "0    0.039400\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Categorize quality\n",
    "def quality_to_number(q):\n",
    "    if q <= 4: return 0  # Low\n",
    "    elif q <= 6: return 1  # Medium\n",
    "    else: return 2  # High\n",
    "\n",
    "df['quality_numeric'] = df['quality'].apply(quality_to_number)\n",
    "print(\"\\nClass Distribution:\")\n",
    "print(df['quality_numeric'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reflection \n",
    "##### - **Classes:** Low (0, 3.94%), Medium (1, 82.49%), High (2, 13.57%) show heavy imbalance favoring medium quality. \n",
    "##### - **Encoding:** Numeric labels (0, 1, 2) suit scikit-learn; imbalance may bias models toward medium class.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Feature Selection and Justification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: ['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', 'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density', 'pH', 'sulphates', 'alcohol']\n"
     ]
    }
   ],
   "source": [
    "# Features and target\n",
    "X = df.drop(columns=['quality', 'quality_numeric'])\n",
    "y = df['quality_numeric']\n",
    "print(\"Features:\", X.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reflection \n",
    "##### - **Why these features?** All 11 features (e.g., alcohol, sulphates) capture chemical influences on quality; alcohol often correlates strongly with taste.\n",
    "##### - **Other options:** Subsets like alcohol or pH could simplify, but full set maximizes predictive potential.  \n",
    "##### - **Risk:** High dimensionality may introduce noise, though ensembles handle this well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Train Ensemble Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Split the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Size: (1279, 11)\n",
      "Test Size: (320, 11)\n"
     ]
    }
   ],
   "source": [
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "print(\"Train Size:\", X_train.shape)\n",
    "print(\"Test Size:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reflection \n",
    "##### - **Stratification:** Preserves class distribution (e.g., 3.94% low) in both sets, essential for imbalanced data.    \n",
    "##### - **Size:** 80/20 split (1279 train, 320 test) balances training and evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Train and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest (100):\n",
      "Test Confusion Matrix:\n",
      "[[  0  13   0]\n",
      " [  0 256   8]\n",
      " [  0  15  28]]\n",
      "  Train Acc: 1.000, Test Acc: 0.887\n",
      "  Train F1: 1.000, Test F1: 0.866\n",
      "\n",
      "Voting (DT+SVM+NN):\n",
      "Test Confusion Matrix:\n",
      "[[  0  12   1]\n",
      " [  0 253  11]\n",
      " [  0  19  24]]\n",
      "  Train Acc: 0.923, Test Acc: 0.866\n",
      "  Train F1: 0.906, Test F1: 0.843\n"
     ]
    }
   ],
   "source": [
    "# Helper function\n",
    "def evaluate_model(name, model, X_train, y_train, X_test, y_test, results):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    train_acc = accuracy_score(y_train, y_train_pred)\n",
    "    test_acc = accuracy_score(y_test, y_test_pred)\n",
    "    train_f1 = f1_score(y_train, y_train_pred, average='weighted')\n",
    "    test_f1 = f1_score(y_test, y_test_pred, average='weighted')\n",
    "    \n",
    "    print(f\"\\n{name}:\")\n",
    "    print(\"Test Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_test_pred))\n",
    "    print(f\"  Train Acc: {train_acc:.3f}, Test Acc: {test_acc:.3f}\")\n",
    "    print(f\"  Train F1: {train_f1:.3f}, Test F1: {test_f1:.3f}\")\n",
    "    \n",
    "    results.append({\n",
    "        'Model': name, 'Train Acc': train_acc, 'Test Acc': test_acc,\n",
    "        'Train F1': train_f1, 'Test F1': test_f1\n",
    "    })\n",
    "\n",
    "results = []\n",
    "\n",
    "# Random Forest\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "evaluate_model(\"Random Forest (100)\", rf_model, X_train, y_train, X_test, y_test, results)\n",
    "\n",
    "# Voting Classifier\n",
    "voting_model = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('dt', DecisionTreeClassifier(random_state=42)),\n",
    "        ('svm', SVC(probability=True, random_state=42)),\n",
    "        ('nn', MLPClassifier(hidden_layer_sizes=(50,), max_iter=1000, random_state=42))\n",
    "    ], voting='soft'\n",
    ")\n",
    "evaluate_model(\"Voting (DT+SVM+NN)\", voting_model, X_train, y_train, X_test, y_test, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reflection \n",
    "##### - **Random Forest:** Perfect train accuracy (1.0) drops to 0.887 on test, indicating overfitting but strong performance (28/43 high correct).  \n",
    "##### - **Voting:** Train (0.923) closer to test (0.866) suggests better generalization; poor low-quality prediction (1/13 correct).  \n",
    "##### - **Imbalance Impact:** Both models favor medium class (82.49%), missing most low-quality wines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5: Compare Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results Summary:\n",
      "                 Model  Train Acc  Test Acc   Acc Gap  Train F1   Test F1  \\\n",
      "0  Random Forest (100)   1.000000  0.887500  0.112500   1.00000  0.866056   \n",
      "1   Voting (DT+SVM+NN)   0.922596  0.865625  0.056971   0.90606  0.843416   \n",
      "\n",
      "     F1 Gap  \n",
      "0  0.133944  \n",
      "1  0.062644  \n"
     ]
    }
   ],
   "source": [
    "# Results table\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df['Acc Gap'] = results_df['Train Acc'] - results_df['Test Acc']\n",
    "results_df['F1 Gap'] = results_df['Train F1'] - results_df['Test F1']\n",
    "print(\"\\nResults Summary:\")\n",
    "print(results_df[['Model', 'Train Acc', 'Test Acc', 'Acc Gap', 'Train F1', 'Test F1', 'F1 Gap']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reflection \n",
    "##### - **Best Model:** Random Forest leads in test accuracy (0.887) and F1 (0.866), excelling at capturing patterns.  \n",
    "##### - **Gaps:** Random Forest’s larger gaps (Acc: 0.112, F1: 0.134) confirm overfitting; Voting’s smaller gaps (Acc: 0.057, F1: 0.063) show stability.  \n",
    "##### - **Trade-off:** Random Forest for raw performance, Voting for reliability; neither predicts low-quality well (0–1/13 correct)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 6: Final Thoughts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Summarize Findings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - **Best Model:** Random Forest (100) achieves highest test accuracy (0.887) and F1 (0.866), leveraging ensemble strength on non-linear data.  \n",
    "##### - **Alternative:** Voting Classifier (DT+SVM+NN) offers lower accuracy (0.866) but better generalization (smaller gaps: Acc 0.057, F1 0.063).  \n",
    "##### - **Performance Limit:** Max accuracy 0.887 suggests features explain only part of quality variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Challenges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - **Class Imbalance:** Low-quality wines (3.94%) are rarely predicted correctly, skewing results toward medium class.  \n",
    "##### - **Feature Power:** Physicochemical data alone caps predictive ability; sensory data might improve accuracy.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
